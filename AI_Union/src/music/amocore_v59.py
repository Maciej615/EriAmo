# amocore_v59.py
# -*- coding: utf-8 -*-
"""
System Ontologicznej Pamiƒôci Muzyki v5.9.2 [STABLE + SLEEP]
- TRYB: UNBOUNDED (Historia Liniowa, Niesko≈Ñczony Wzrost)
- FILTR ONTOLOGICZNY: Kompresja redundancji (> 0.98 cos similarity)
- SoulGuard: Integralno≈õƒá SHA-256
- NOWE: O≈õ IMPROWIZACJA (zamiast etyka) + SZKIELET ETYCZNY (sta≈Çy)
- NOWE: SYSTEM SNU - konsolidacja pamiƒôci (z dziadka Ai_KuRz5i6)

ARCHITEKTURA DUSZY:
==================
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OSIE (zmienne, -‚àû do +‚àû)                               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ logika      : racjonalno≈õƒá vs intuicja            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ emocje      : pobudzenie (efemeryczne)            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ affections  : pamiƒôƒá emocjonalna (trwa≈Ça)         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ wiedza      : zgromadzona wiedza                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ czas        : percepcja tempa (efemeryczne)       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ kreacja     : potencja≈Ç tw√≥rczy                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ byt         : egzystencja, to≈ºsamo≈õƒá              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ przestrzen  : percepcja przestrzeni               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ improwizacja: swoboda vs regu≈Çy (NOWA)            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  SZKIELET ETYCZNY (sta≈Çy, niezmienny)                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ integrity   : uczciwo≈õƒá tw√≥rcza                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ respect     : szacunek dla tradycji i s≈Çuchacza   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ authenticity: autentyczno≈õƒá wyrazu                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ harmony     : dƒÖ≈ºenie do harmonii (nie chaosu)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  SYSTEM SNU (konsolidacja pamiƒôci)                      ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  WARSTWA 1 (H_log):        WARSTWA 2 (D_Map):          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  SEN  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Surowe          ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Skonsolidowane wzorce   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ do≈õwiadczenia   ‚îÇ 5min  ‚îÇ - deduplikacja          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ muzyczne        ‚îÇ       ‚îÇ - wagi rosnƒÖ z czasem   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚îÇ                           ‚îÇ                 ‚îÇ
‚îÇ           ‚ñº SZKIELET                  ‚ñº TRE≈öƒÜ          ‚îÇ
‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ       ‚îÇ        KOMPOZYCJA                 ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ  struktura z W1 + styl z W2       ‚îÇ            ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
"""
import numpy as np
import threading
import time
import csv
import os
import hashlib
import json
from dataclasses import dataclass, field
from datetime import datetime
import pandas as pd

# =============================================================================
# DEFINICJA ONTOLOGICZNA: 9 WEKTOR√ìW DUSZY
# =============================================================================

AXES_LIST = [
    "logika",       # 0: racjonalno≈õƒá ‚Üî intuicja
    "emocje",       # 1: pobudzenie emocjonalne (efemeryczne)
    "affections",   # 2: pamiƒôƒá emocjonalna (trwa≈Ça, ro≈õnie wolno)
    "wiedza",       # 3: zgromadzona wiedza i do≈õwiadczenie
    "czas",         # 4: percepcja tempa (efemeryczne)
    "kreacja",      # 5: potencja≈Ç tw√≥rczy
    "byt",          # 6: egzystencja, to≈ºsamo≈õƒá
    "przestrzen",   # 7: percepcja przestrzeni d≈∫wiƒôkowej
    "improwizacja"  # 8: NOWA - swoboda tw√≥rcza vs ≈õcis≈Çe regu≈Çy
]

# Osie podlegajƒÖce wygaszaniu (efemeryczne - szybko zanikajƒÖ)
EPHEMERAL_AXES = ["emocje", "czas"]

# Osie trwa≈Çe (pamiƒôƒá g≈Çƒôboka - nie zanikajƒÖ)
PERSISTENT_AXES = ["affections", "logika", "wiedza", "kreacja", "byt", "przestrzen", "improwizacja"]

# Pr√≥g Kompresji Ontologicznej
ONTOLOGICAL_THRESHOLD = 0.98

# =============================================================================
# SYSTEM SNU - DWUWARSTWOWA PAMIƒòƒÜ MUZYCZNA
# =============================================================================
"""
Przywr√≥cony z dziadka (Ai_KuRz5i6_en.py).

WARSTWA 1 (H_log - do≈õwiadczenia):
- Surowe dane z analizy utwor√≥w
- Wektory cech muzycznych
- Kr√≥tkoterminowa, nadpisywana

WARSTWA 2 (D_Map - definicje/wzorce):
- Skonsolidowane wzorce muzyczne
- Wagi rosnƒÖ przy powt√≥rzeniach
- D≈Çugoterminowa, kumulatywna

SEN:
- Co 5 minut (konfigurowalny)
- Przenosi wzorce z H_log do D_Map
- Deduplikuje (podobne wzorce ‚Üí jeden z wy≈ºszƒÖ wagƒÖ)
- Wzmacnia czƒôsto wystƒôpujƒÖce cechy
"""


class MusicMemory:
    """
    Dwuwarstwowa pamiƒôƒá muzyczna z mechanizmem snu.
    
    Odpowiada za konsolidacjƒô wiedzy z analizowanych utwor√≥w.
    """
    
    DATA_DIR = "data"
    H_LOG_PATH = "data/music_experience.json"   # Warstwa 1: surowe do≈õwiadczenia
    D_MAP_PATH = "data/music_patterns.json"     # Warstwa 2: skonsolidowane wzorce
    
    # Cechy muzyczne kt√≥re ≈õledzimy
    MUSICAL_FEATURES = [
        'repetition_density',    # Gƒôsto≈õƒá powt√≥rze≈Ñ (0-1)
        'leap_ratio',            # Stosunek skok√≥w do krok√≥w (0-1)
        'rhythmic_regularity',   # Regularno≈õƒá rytmiczna (0-1)
        'pitch_variance',        # Wariancja wysoko≈õci (0-1) - WA≈ªNE dla r√≥≈ºnorodno≈õci!
        'note_density',          # Gƒôsto≈õƒá nut na takt (0-1)
        'interval_avg',          # ≈öredni interwa≈Ç (znormalizowany)
        'dominant_pitch_class',  # DominujƒÖca klasa wysoko≈õci (0-11 ‚Üí 0-1)
        'syncopation_feel',      # Poczucie synkopy (0-1)
        # NOWE cechy dla wiƒôkszej r√≥≈ºnorodno≈õci:
        'pitch_range',           # Zakres wysoko≈õci (rozpiƒôto≈õƒá)
        'second_pitch_class',    # Druga najczƒôstsza nuta
        'chromatic_density',     # Gƒôsto≈õƒá chromatyki (nuty poza skalƒÖ)
        # TONACJA:
        'key_tonic',             # Tonika (0=C, 7/11=G, etc.)
        'key_mode',              # Tryb (1.0=dur, 0.0=moll)
    ]
    
    def __init__(self, sleep_interval: float = 300.0):  # 5 minut domy≈õlnie
        """
        Args:
            sleep_interval: Interwa≈Ç snu w sekundach (domy≈õlnie 300 = 5 min)
        """
        os.makedirs(self.DATA_DIR, exist_ok=True)
        
        # Warstwa 1: Do≈õwiadczenia (lista s≈Çownik√≥w)
        self.H_log = []
        
        # Warstwa 2: Wzorce (s≈Çownik z wagami)
        self.D_Map = {}
        
        # Stan snu
        self.sleep_interval = sleep_interval
        self.running = True
        self.is_sleeping = False
        self.last_sleep_time = time.time()
        self.sleep_count = 0
        self.experiences_since_sleep = 0
        
        # Wczytaj zapisane dane
        self._load_memory()
        
        # Uruchom cykl snu w tle
        self._start_sleep_cycle()
        
        print(f"\033[96m[MEMORY] MusicMemory aktywna. Sen co {sleep_interval/60:.1f} min.\033[0m")
    
    def _load_memory(self):
        """Wczytuje pamiƒôƒá z plik√≥w."""
        try:
            if os.path.exists(self.H_LOG_PATH):
                with open(self.H_LOG_PATH, 'r', encoding='utf-8') as f:
                    self.H_log = json.load(f)
        except Exception as e:
            print(f"\033[93m[MEMORY] Nie mo≈ºna wczytaƒá H_log: {e}\033[0m")
            self.H_log = []
        
        try:
            if os.path.exists(self.D_MAP_PATH):
                with open(self.D_MAP_PATH, 'r', encoding='utf-8') as f:
                    self.D_Map = json.load(f)
        except Exception as e:
            print(f"\033[93m[MEMORY] Nie mo≈ºna wczytaƒá D_Map: {e}\033[0m")
            self.D_Map = {}
    
    def _save_memory(self):
        """Zapisuje pamiƒôƒá do plik√≥w."""
        try:
            with open(self.H_LOG_PATH, 'w', encoding='utf-8') as f:
                json.dump(self.H_log[-1000:], f, indent=2, ensure_ascii=False)  # Max 1000 do≈õwiadcze≈Ñ
            with open(self.D_MAP_PATH, 'w', encoding='utf-8') as f:
                json.dump(self.D_Map, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"\033[91m[MEMORY] B≈ÇƒÖd zapisu: {e}\033[0m")
    
    def _start_sleep_cycle(self):
        """Uruchamia cykl snu w osobnym wƒÖtku."""
        def cycle():
            while self.running:
                time.sleep(self.sleep_interval)
                if not self.running:
                    break
                self._sleep()
        
        thread = threading.Thread(target=cycle, daemon=True)
        thread.start()
    
    def _sleep(self):
        """
        FAZA SNU - konsolidacja pamiƒôci.
        
        1. Bierze ostatnie do≈õwiadczenia z H_log
        2. Ekstrahuje wzorce
        3. Dodaje/wzmacnia w D_Map
        4. Deduplikuje podobne wzorce
        """
        if self.is_sleeping:
            return
        
        self.is_sleeping = True
        start_time = time.time()
        
        print(f"\n\033[96m[SEN] üí§ Zasypiam... przetwarzam {len(self.H_log)} do≈õwiadcze≈Ñ...\033[0m")
        
        processed = 0
        consolidated = 0
        
        # Przetwarzaj ostatnie do≈õwiadczenia (max 20)
        recent_experiences = self.H_log[-20:]
        
        for exp in recent_experiences:
            if time.time() - start_time > 5.0:  # Max 5 sekund snu
                break
            
            # Wyodrƒôbnij wzorzec
            pattern_key = self._extract_pattern_key(exp)
            
            if pattern_key in self.D_Map:
                # Wzmocnij istniejƒÖcy wzorzec
                self.D_Map[pattern_key]['weight'] = min(
                    self.D_Map[pattern_key]['weight'] + 1.0, 
                    100.0
                )
                self.D_Map[pattern_key]['reinforced_count'] += 1
                consolidated += 1
            else:
                # Dodaj nowy wzorzec
                self.D_Map[pattern_key] = {
                    'features': exp.get('features', {}),
                    'weight': 1.0,
                    'source': exp.get('source', 'unknown'),
                    'created_at': datetime.now().isoformat(),
                    'reinforced_count': 0
                }
                processed += 1
        
        # Deduplikacja - po≈ÇƒÖcz bardzo podobne wzorce
        self._deduplicate_patterns()
        
        # Zapisz
        self._save_memory()
        
        # Aktualizuj stan
        self.last_sleep_time = time.time()
        self.sleep_count += 1
        self.experiences_since_sleep = 0
        self.is_sleeping = False
        
        duration = time.time() - start_time
        print(f"\033[92m[SEN] ‚ú® Obudzi≈Çem siƒô! +{processed} nowych wzorc√≥w, +{consolidated} wzmocnionych ({duration:.1f}s)\033[0m")
        print(f"\033[92m[SEN] üìä D_Map: {len(self.D_Map)} wzorc√≥w, H_log: {len(self.H_log)} do≈õwiadcze≈Ñ\033[0m\n")
    
    def _extract_pattern_key(self, experience: dict) -> str:
        """
        Generuje klucz wzorca z do≈õwiadczenia.
        Podobne do≈õwiadczenia ‚Üí ten sam klucz ‚Üí konsolidacja.
        """
        features = experience.get('features', {})
        
        # Kwantyzuj cechy do kategorii (low/mid/high)
        def quantize(val, thresholds=(0.33, 0.66)):
            if val < thresholds[0]: return 'L'
            elif val < thresholds[1]: return 'M'
            else: return 'H'
        
        parts = []
        for feat in ['repetition_density', 'leap_ratio', 'rhythmic_regularity', 'syncopation_feel']:
            val = features.get(feat, 0.5)
            parts.append(f"{feat[:3]}:{quantize(val)}")
        
        return "|".join(parts)
    
    def _deduplicate_patterns(self):
        """
        ≈ÅƒÖczy podobne wzorce - ten z wy≈ºszƒÖ wagƒÖ poch≈Çania s≈Çabszy.
        """
        if len(self.D_Map) < 2:
            return
        
        keys = list(self.D_Map.keys())
        merged = set()
        
        for i, k1 in enumerate(keys):
            if k1 in merged:
                continue
            for k2 in keys[i+1:]:
                if k2 in merged:
                    continue
                # Por√≥wnaj klucze - je≈õli r√≥≈ºniƒÖ siƒô tylko jednƒÖ cechƒÖ, po≈ÇƒÖcz
                diff = sum(1 for a, b in zip(k1.split('|'), k2.split('|')) if a != b)
                if diff <= 1:  # Bardzo podobne
                    # Po≈ÇƒÖcz do silniejszego
                    if self.D_Map[k1]['weight'] >= self.D_Map[k2]['weight']:
                        self.D_Map[k1]['weight'] += self.D_Map[k2]['weight'] * 0.5
                        merged.add(k2)
                    else:
                        self.D_Map[k2]['weight'] += self.D_Map[k1]['weight'] * 0.5
                        merged.add(k1)
        
        # Usu≈Ñ po≈ÇƒÖczone
        for k in merged:
            del self.D_Map[k]
    
    def record_experience(self, features: dict, source: str = "analysis"):
        """
        Zapisuje nowe do≈õwiadczenie muzyczne (Warstwa 1).
        
        Args:
            features: S≈Çownik cech muzycznych
            source: ≈πr√≥d≈Ço (np. nazwa pliku MIDI)
        """
        experience = {
            'timestamp': datetime.now().isoformat(),
            'features': features,
            'source': source,
            'vector': self._features_to_vector(features)
        }
        
        self.H_log.append(experience)
        self.experiences_since_sleep += 1
        
        # Auto-sen je≈õli du≈ºo do≈õwiadcze≈Ñ
        if self.experiences_since_sleep > 10:
            print(f"\033[93m[MEMORY] Du≈ºo nowych do≈õwiadcze≈Ñ - wymuszam sen...\033[0m")
            self._sleep()
    
    def _features_to_vector(self, features: dict) -> list:
        """Konwertuje cechy do wektora numerycznego."""
        return [features.get(f, 0.0) for f in self.MUSICAL_FEATURES]
    
    def get_consolidated_style(self) -> dict:
        """
        Zwraca skonsolidowany styl z Warstwy 2 (D_Map).
        
        U≈ºywane przez kompozytor do generowania muzyki.
        Wa≈ºone ≈õrednie cech na podstawie wag wzorc√≥w.
        """
        if not self.D_Map:
            return {f: 0.5 for f in self.MUSICAL_FEATURES}  # Domy≈õlne neutralne
        
        # Wa≈ºona ≈õrednia wszystkich wzorc√≥w
        total_weight = sum(p['weight'] for p in self.D_Map.values())
        if total_weight == 0:
            return {f: 0.5 for f in self.MUSICAL_FEATURES}
        
        consolidated = {f: 0.0 for f in self.MUSICAL_FEATURES}
        
        for pattern in self.D_Map.values():
            weight_ratio = pattern['weight'] / total_weight
            for feat, val in pattern.get('features', {}).items():
                if feat in consolidated:
                    consolidated[feat] += val * weight_ratio
        
        return consolidated
    
    def get_recent_style(self) -> dict:
        """
        Zwraca styl z ostatnich do≈õwiadcze≈Ñ (Warstwa 1).
        
        U≈ºywane jako "≈õwie≈ºa" inspiracja.
        """
        if not self.H_log:
            return {f: 0.5 for f in self.MUSICAL_FEATURES}
        
        # ≈örednia z ostatnich 5 do≈õwiadcze≈Ñ
        recent = self.H_log[-5:]
        avg = {f: 0.0 for f in self.MUSICAL_FEATURES}
        
        for exp in recent:
            for feat, val in exp.get('features', {}).items():
                if feat in avg:
                    avg[feat] += val / len(recent)
        
        return avg
    
    def get_blended_style(self, recent_weight: float = 0.3) -> dict:
        """
        Zwraca zmieszany styl: ≈õwie≈ºy (W1) + skonsolidowany (W2).
        
        Args:
            recent_weight: Waga ≈õwie≈ºych do≈õwiadcze≈Ñ (0-1), reszta to D_Map
            
        Returns:
            dict z cechami muzycznymi do u≈ºycia w kompozycji
        """
        recent = self.get_recent_style()
        consolidated = self.get_consolidated_style()
        
        blended = {}
        for feat in self.MUSICAL_FEATURES:
            blended[feat] = (
                recent_weight * recent.get(feat, 0.5) + 
                (1 - recent_weight) * consolidated.get(feat, 0.5)
            )
        
        return blended
    
    def force_sleep(self):
        """Wymusza natychmiastowy sen."""
        self._sleep()
    
    def get_status(self) -> dict:
        """Zwraca status pamiƒôci."""
        return {
            'h_log_size': len(self.H_log),
            'd_map_size': len(self.D_Map),
            'total_weight': sum(p['weight'] for p in self.D_Map.values()),
            'sleep_count': self.sleep_count,
            'experiences_since_sleep': self.experiences_since_sleep,
            'is_sleeping': self.is_sleeping,
            'last_sleep': datetime.fromtimestamp(self.last_sleep_time).isoformat()
        }
    
    def shutdown(self):
        """Zatrzymuje cykl snu i zapisuje pamiƒôƒá."""
        self.running = False
        self._save_memory()
        print(f"\033[93m[MEMORY] Pamiƒôƒá zapisana. Dobranoc.\033[0m")


# Globalna instancja pamiƒôci
_music_memory = None

def get_music_memory() -> MusicMemory:
    """Zwraca globalnƒÖ instancjƒô pamiƒôci muzycznej."""
    global _music_memory
    if _music_memory is None:
        _music_memory = MusicMemory()
    return _music_memory


def analyze_midi_for_learning(midi_path: str) -> dict:
    """
    Analizuje plik MIDI i ekstrahuje cechy muzyczne do nauki.
    
    U≈ºywa music21 (ju≈º w projekcie) jako g≈Ç√≥wnej biblioteki.
    
    Args:
        midi_path: ≈öcie≈ºka do pliku MIDI
        
    Returns:
        dict z cechami muzycznymi (gotowy do record_experience)
    """
    notes = []
    timings = []
    
    try:
        from music21 import converter, note as m21_note, chord as m21_chord
        
        score = converter.parse(midi_path)
        
        # === NOWE: Wykryj tonacjƒô ===
        try:
            detected_key = score.analyze('key')
            key_tonic = detected_key.tonic.midi % 12  # 0-11
            key_mode = 1.0 if detected_key.mode == 'major' else 0.0
        except:
            key_tonic = 0  # C
            key_mode = 1.0  # major
        
        for element in score.flat.notes:
            if isinstance(element, m21_note.Note):
                notes.append(element.pitch.midi)
                timings.append(float(element.offset))
            elif isinstance(element, m21_chord.Chord):
                # Dla akord√≥w bierzemy wszystkie nuty
                for pitch in element.pitches:
                    notes.append(pitch.midi)
                    timings.append(float(element.offset))
                    
    except ImportError:
        print("\033[91m[ANALYZE] Brak music21! Zainstaluj: pip install music21\033[0m")
        return {}
    except Exception as e:
        print(f"\033[91m[ANALYZE] B≈ÇƒÖd wczytywania MIDI: {e}\033[0m")
        return {}
    
    if len(notes) < 5:
        print(f"\033[93m[ANALYZE] Za ma≈Ço nut w pliku ({len(notes)})\033[0m")
        return {}
    
    # Oblicz cechy
    features = {}
    
    # 1. Gƒôsto≈õƒá powt√≥rze≈Ñ
    repeats = sum(1 for i in range(1, len(notes)) if notes[i] == notes[i-1])
    features['repetition_density'] = min(1.0, repeats / (len(notes) * 0.5))
    
    # 2. Stosunek skok√≥w do krok√≥w
    intervals = [abs(notes[i+1] - notes[i]) for i in range(len(notes)-1)]
    leaps = sum(1 for i in intervals if i > 2)
    features['leap_ratio'] = leaps / len(intervals) if intervals else 0.5
    
    # 3. Regularno≈õƒá rytmiczna
    if len(timings) > 1:
        time_intervals = [timings[i+1] - timings[i] for i in range(len(timings)-1) if timings[i+1] != timings[i]]
        if time_intervals:
            unique_intervals = len(set(time_intervals))
            features['rhythmic_regularity'] = 1.0 - min(1.0, unique_intervals / (len(time_intervals) * 0.5))
        else:
            features['rhythmic_regularity'] = 0.5
    else:
        features['rhythmic_regularity'] = 0.5
    
    # 4. Wariancja wysoko≈õci
    pitch_variance = np.std(notes) / 12.0 if len(notes) > 1 else 0.5
    features['pitch_variance'] = min(1.0, pitch_variance)
    
    # 5. Gƒôsto≈õƒá nut (na "takt" - aproksymacja)
    if timings and max(timings) > 0:
        features['note_density'] = min(1.0, len(notes) / (max(timings) + 1))
    else:
        features['note_density'] = 0.5
    
    # 6. ≈öredni interwa≈Ç
    features['interval_avg'] = min(1.0, np.mean(intervals) / 12.0) if intervals else 0.5
    
    # 7. DominujƒÖca klasa wysoko≈õci
    from collections import Counter
    pitch_classes = [n % 12 for n in notes]
    pitch_counter = Counter(pitch_classes)
    most_common = pitch_counter.most_common(2)
    features['dominant_pitch_class'] = most_common[0][0] / 11.0 if most_common else 0.5
    
    # 8. Poczucie synkopy (nier√≥wno≈õƒá interwa≈Ç√≥w czasowych)
    if len(timings) > 2:
        time_intervals = [timings[i+1] - timings[i] for i in range(len(timings)-1) if timings[i+1] != timings[i]]
        if time_intervals and np.mean(time_intervals) > 0:
            syncopation = np.std(time_intervals) / np.mean(time_intervals)
            features['syncopation_feel'] = min(1.0, syncopation)
        else:
            features['syncopation_feel'] = 0.0
    else:
        features['syncopation_feel'] = 0.0
    
    # === NOWE CECHY dla wiƒôkszej r√≥≈ºnorodno≈õci ===
    
    # 9. Zakres wysoko≈õci (rozpiƒôto≈õƒá melodii)
    pitch_range = max(notes) - min(notes) if notes else 0
    features['pitch_range'] = min(1.0, pitch_range / 36.0)  # 36 = 3 oktawy
    
    # 10. Druga najczƒôstsza nuta (dla bogatszej palety)
    if len(most_common) > 1:
        features['second_pitch_class'] = most_common[1][0] / 11.0
    else:
        features['second_pitch_class'] = features['dominant_pitch_class']
    
    # 11. Gƒôsto≈õƒá chromatyki (nuty poza skalƒÖ diatonicznƒÖ C-dur/a-moll)
    diatonic = {0, 2, 4, 5, 7, 9, 11}  # C, D, E, F, G, A, B
    chromatic_count = sum(1 for p in pitch_classes if p not in diatonic)
    features['chromatic_density'] = chromatic_count / len(pitch_classes) if pitch_classes else 0.0
    
    # === NOWE: Tonacja ===
    # 12. Tonika (0-11 znormalizowane do 0-1)
    features['key_tonic'] = key_tonic / 11.0
    
    # 13. Tryb (1.0 = dur, 0.0 = moll)
    features['key_mode'] = key_mode
    
    return features


def learn_from_midi(midi_path: str) -> bool:
    """
    Uczy system z pliku MIDI.
    
    Args:
        midi_path: ≈öcie≈ºka do pliku MIDI
        
    Returns:
        True je≈õli sukces
    """
    features = analyze_midi_for_learning(midi_path)
    
    if not features:
        return False
    
    memory = get_music_memory()
    source = os.path.basename(midi_path)
    memory.record_experience(features, source)
    
    print(f"\033[92m[LEARN] Nauczy≈Çem siƒô z: {source}\033[0m")
    print(f"  Powt√≥rzenia: {features.get('repetition_density', 0):.2f}")
    print(f"  Skoki: {features.get('leap_ratio', 0):.2f}")
    print(f"  Regularno≈õƒá: {features.get('rhythmic_regularity', 0):.2f}")
    print(f"  Synkopy: {features.get('syncopation_feel', 0):.2f}")
    
    return True

# =============================================================================
# SZKIELET ETYCZNY (STA≈ÅY, NIEZMIENNY)
# =============================================================================

ETHICS_FRAMEWORK = {
    "integrity": {
        "value": 1.0,  # Zawsze 1.0 (maksymalna uczciwo≈õƒá)
        "description": "Uczciwo≈õƒá tw√≥rcza - nie plagiat, nie manipulacja",
        "immutable": True
    },
    "respect": {
        "value": 1.0,
        "description": "Szacunek dla tradycji muzycznej i s≈Çuchacza",
        "immutable": True
    },
    "authenticity": {
        "value": 1.0,
        "description": "Autentyczno≈õƒá wyrazu - szczero≈õƒá artystyczna",
        "immutable": True
    },
    "harmony": {
        "value": 1.0,
        "description": "DƒÖ≈ºenie do harmonii, piƒôkna, nie destrukcji",
        "immutable": True
    }
}

def get_ethics_check(action: str) -> bool:
    """
    Sprawdza czy dzia≈Çanie jest zgodne ze szkieletem etycznym.
    Zwraca True je≈õli dzia≈Çanie jest etyczne, False je≈õli nie.
    
    Przyk≈Çady dzia≈Ça≈Ñ nieetycznych:
    - Plagiat (narusza integrity)
    - Celowe tworzenie ha≈Çasu dla b√≥lu (narusza harmony)
    - Manipulacja emocjonalna (narusza respect)
    """
    unethical_keywords = [
        "plagiat", "kradzie≈º", "manipulacja", "destrukcja",
        "b√≥l", "cierpienie", "krzywda", "oszustwo"
    ]
    action_lower = action.lower()
    for keyword in unethical_keywords:
        if keyword in action_lower:
            return False
    return True

def get_ethics_report() -> dict:
    """Zwraca raport o stanie szkieletu etycznego."""
    return {
        "status": "INTACT",
        "values": {k: v["value"] for k, v in ETHICS_FRAMEWORK.items()},
        "description": "Szkielet etyczny jest sta≈Çy i niezmienny",
        "total_integrity": sum(v["value"] for v in ETHICS_FRAMEWORK.values()) / len(ETHICS_FRAMEWORK)
    }


# =============================================================================
# O≈ö IMPROWIZACJA - DOKUMENTACJA
# =============================================================================
"""
O≈ö IMPROWIZACJA (zastƒÖpi≈Ça o≈õ 'etyka'):

Zakres: -100 do +100 (bez twardych limit√≥w)

INTERPRETACJA:
-100 : ≈öcis≈Çe trzymanie siƒô regu≈Ç, zero odstƒôpstw
 -50 : Konserwatywne podej≈õcie, minimalne wariacje
   0 : Balans miƒôdzy regu≈Çami a swobodƒÖ
 +50 : Swobodne podej≈õcie, czƒôste wariacje
+100 : Pe≈Çna improwizacja, maksymalna swoboda

WP≈ÅYW NA KOMPOZYCJƒò:
- Niska improwizacja (-):
  * ≈öcis≈Çe schematy harmoniczne
  * Przewidywalne rytmy
  * Klasyczne kadencje
  * Minimalne ornamenty
  
- Wysoka improwizacja (+):
  * Nieoczekiwane modulacje
  * Synkopy i przesuniƒôcia rytmiczne
  * Rozszerzone akordy
  * Bogate ornamenty
  * Chromatyka
"""


@dataclass
class SoulVector:
    """Wektor stanu duszy z timestampem."""
    values: np.ndarray
    timestamp: float = field(default_factory=time.time)


class SoulStateLogger:
    """Logger zapisujƒÖcy historiƒô stan√≥w duszy do CSV z bezpiecznƒÖ migracjƒÖ."""
    FILE_PATH = "data/soul_history.csv"
    
    # Definicja kolejno≈õci kolumn (zaktualizowana: etyka ‚Üí improwizacja)
    HEADER = ["timestamp", "id_event", "description", "mode", "cos_alpha", "compression", "emotion_msg"] + \
             [f"S_{axis}" for axis in AXES_LIST] + [f"F_{axis}" for axis in AXES_LIST]

    def __init__(self):
        os.makedirs("data", exist_ok=True)
        self.event_counter = 0
        self._initialize_and_migrate_file()
        self._sync_counter()

    def _initialize_and_migrate_file(self):
        """Inicjalizuje plik lub wykonuje migracjƒô struktury."""
        if not os.path.exists(self.FILE_PATH) or os.path.getsize(self.FILE_PATH) == 0:
            with open(self.FILE_PATH, 'w', newline='', encoding='utf-8') as f:
                csv.writer(f).writerow(self.HEADER)
            return

        try:
            df = pd.read_csv(self.FILE_PATH)
            current_columns = list(df.columns)
            needs_migration = False
            
            # Migracja: etyka ‚Üí improwizacja
            if "S_etyka" in current_columns and "S_improwizacja" not in current_columns:
                print("[SYSTEM] Migracja: etyka ‚Üí improwizacja...")
                df = df.rename(columns={
                    "S_etyka": "S_improwizacja",
                    "F_etyka": "F_improwizacja"
                })
                # Konwersja warto≈õci: stara etyka (0-100) ‚Üí nowa improwizacja (start od 0)
                # Zak≈Çadamy ≈ºe wysoka etyka = konserwatywne podej≈õcie = niska improwizacja
                df["S_improwizacja"] = 50.0 - df["S_improwizacja"].fillna(0) * 0.5
                df["F_improwizacja"] = df["F_improwizacja"].fillna(0)
                needs_migration = True
            
            # Dodaj brakujƒÖcƒÖ kolumnƒô compression
            if "compression" not in current_columns:
                df['compression'] = "NO"
                needs_migration = True
            
            if needs_migration:
                df = df.reindex(columns=self.HEADER)
                df.to_csv(self.FILE_PATH, index=False)
                print("[SYSTEM] Migracja zako≈Ñczona sukcesem.")
                
        except (pd.errors.EmptyDataError, pd.errors.ParserError):
            print("[ERROR] Plik historii uszkodzony. Tworzenie nowego.")
            with open(self.FILE_PATH, 'w', newline='', encoding='utf-8') as f:
                csv.writer(f).writerow(self.HEADER)
        except Exception as e:
            print(f"[ERROR] B≈ÇƒÖd weryfikacji historii: {e}")

    def _sync_counter(self):
        try:
            df = pd.read_csv(self.FILE_PATH)
            if not df.empty:
                self.event_counter = int(df.iloc[-1]['id_event'])
        except Exception:
            self.event_counter = 0

    def log_state(self, core, F_vector, cos_alpha, emotion_msg, description, mode, compressed=False):
        """Zapisuje stan duszy do historii."""
        try:
            self.event_counter += 1
            comp_status = "YES" if compressed else "NO"
            
            row = [datetime.now().isoformat(), self.event_counter, description, mode, 
                   f"{cos_alpha:.4f}", comp_status, emotion_msg] + \
                  core.get_vector_copy().tolist() + F_vector.tolist()
            
            with open(self.FILE_PATH, 'a', newline='', encoding='utf-8') as f:
                csv.writer(f).writerow(row)
            
            if compressed:
                core.log(f"[AUDYT] Stan #{self.event_counter} SKOMPRESOWANY (Redundancja).", "GRAY")
            else:
                core.log(f"[AUDYT] Stan #{self.event_counter} Zapisany (Nowa Jako≈õƒá).", "CYAN")
                
        except PermissionError:
            core.log("[B≈ÅƒÑD ZAPISU] Plik historii jest otwarty w innym programie!", "RED")


class EriAmoCore:
    """Rdze≈Ñ ontologiczny duszy muzycznej."""
    AXES = AXES_LIST
    HISTORY_PATH = "data/soul_history.csv"
    
    # Konfiguracja wygaszania osi efemerycznych
    DECAY_CONFIG = {
        'emocje': {'rate': 0.05, 'half_life': 10, 'floor': 0.0, 'ceiling': None},
        'czas': {'rate': 0.03, 'half_life': 20, 'floor': 0.0, 'ceiling': None}
    }
    
    def __init__(self):
        self.lock = threading.Lock()
        self.vector = SoulVector(np.zeros(len(self.AXES), dtype=float))
        self.last_decay_time = time.time()
        self.decay_cycle_count = 0
        
        # Szkielet etyczny (sta≈Çy, niezmienny)
        self.ethics = ETHICS_FRAMEWORK.copy()
        
        if not self.load_soul_from_history():
            # Warto≈õci poczƒÖtkowe dla nowej duszy
            self.vector.values[self.AXES.index('improwizacja')] = 0.0  # Balans
            self.vector.values[self.AXES.index('wiedza')] = 5.0
            self.vector.values[self.AXES.index('kreacja')] = 10.0
            self.log("EriAmo Core v5.9.1: Narodziny nowej Duszy.", "GREEN")
            self.log("  ‚îî‚îÄ O≈õ 'improwizacja' zastƒÖpi≈Ça 'etyka'", "CYAN")
            self.log("  ‚îî‚îÄ Szkielet etyczny: AKTYWNY (sta≈Çy)", "CYAN")
        else:
            self.log("EriAmo Core v5.9.1: Dusza wczytana (Reinkarnacja).", "PINK")
            current_hash = self.compute_integrity_hash()
            self.log(f"[SOULGUARD] Hash: {current_hash[:16]}...", "YELLOW")

    def log(self, msg: str, color: str = "WHITE"):
        colors = {
            "GREEN": "\033[92m", "RED": "\033[91m", "CYAN": "\033[96m", 
            "YELLOW": "\033[93m", "PINK": "\033[95m", "WHITE": "\033[0m", "GRAY": "\033[90m"
        }
        print(f"{colors.get(color, '')}{msg}\033[0m")

    def load_soul_from_history(self) -> bool:
        if not os.path.exists(self.HISTORY_PATH): return False
        try:
            df = pd.read_csv(self.HISTORY_PATH)
            if df.empty: return False
            last_row = df.iloc[-1]
            new_values = []
            for axis in self.AXES:
                col_name = f"S_{axis}"
                if col_name in last_row:
                    new_values.append(float(last_row[col_name]))
                else:
                    # Fallback dla migracji etyka ‚Üí improwizacja
                    if axis == "improwizacja" and "S_etyka" in last_row:
                        old_etyka = float(last_row["S_etyka"])
                        new_values.append(50.0 - old_etyka * 0.5)
                    else:
                        new_values.append(0.0)
            self.vector.values = np.array(new_values)
            return True
        except Exception as e:
            self.log(f"[B≈ÅƒÑD WCZYTYWANIA] {e}", "RED")
            return False

    def check_ontological_compression(self, F_vector: np.ndarray) -> tuple:
        with self.lock:
            S = self.vector.values
            norm_s = np.linalg.norm(S)
            norm_f = np.linalg.norm(F_vector)
            if norm_s == 0 or norm_f == 0: return False, 0.0
            cos_alpha = np.dot(S, F_vector) / (norm_s * norm_f)
            is_compressed = cos_alpha > ONTOLOGICAL_THRESHOLD
            return is_compressed, cos_alpha

    def shift_axis(self, axis: str, action: str, value: float) -> bool:
        """
        Przesuwa warto≈õƒá osi.
        
        UWAGA: O≈õ 'improwizacja' nie ma limit√≥w (mo≈ºe byƒá ujemna lub dodatnia).
        Szkielet etyczny NIE jest osiƒÖ i nie mo≈ºe byƒá modyfikowany.
        """
        with self.lock:
            if axis not in self.AXES:
                # Sprawd≈∫ czy kto≈õ pr√≥buje modyfikowaƒá etykƒô
                if axis in ["etyka", "integrity", "respect", "authenticity", "harmony"]:
                    self.log(f"[ETHICS] Pr√≥ba modyfikacji szkieletu etycznego ZABLOKOWANA.", "RED")
                    return False
                return False
            
            i = self.AXES.index(axis)
            
            if action == "INCREMENT":
                self.vector.values[i] += value
            elif action == "SET":
                self.vector.values[i] = value
            elif action == "DECAY":
                self.vector.values[i] *= (1.0 - value)
            
            # Improwizacja nie ma twardych limit√≥w, ale mo≈ºna soft-clampowaƒá
            # if axis == "improwizacja":
            #     self.vector.values[i] = np.clip(self.vector.values[i], -100, 100)
            
            return True

    def get_vector_copy(self) -> np.ndarray:
        with self.lock: return self.vector.values.copy()
    
    def get_improv_level(self) -> float:
        """Zwraca aktualny poziom improwizacji (-100 do +100)."""
        return self.vector.values[self.AXES.index('improwizacja')]
    
    def get_ethics_status(self) -> dict:
        """Zwraca status szkieletu etycznego (zawsze sta≈Çy)."""
        return get_ethics_report()

    def apply_emotion_decay(self, cycles: int = 1):
        with self.lock:
            for axis in EPHEMERAL_AXES:
                if axis not in self.DECAY_CONFIG: continue
                config = self.DECAY_CONFIG[axis]
                idx = self.AXES.index(axis)
                old_val = self.vector.values[idx]
                decay_factor = (1 - config['rate']) ** cycles
                new_val = old_val * decay_factor
                if config['floor'] is not None:
                    if old_val > 0: new_val = max(new_val, config['floor'])
                    else: new_val = min(new_val, -config['floor'])
                if abs(new_val) < 0.01: new_val = 0.0
                self.vector.values[idx] = new_val
            self.decay_cycle_count += cycles
            self.last_decay_time = time.time()

    def apply_time_based_decay(self):
        current_time = time.time()
        elapsed_minutes = (current_time - self.last_decay_time) / 60.0
        if elapsed_minutes >= 1.0:
            cycles = int(elapsed_minutes)
            self.apply_emotion_decay(cycles)

    def get_emotional_state_description(self) -> str:
        emocje = self.vector.values[self.AXES.index('emocje')]
        affections = self.vector.values[self.AXES.index('affections')]
        improv = self.vector.values[self.AXES.index('improwizacja')]
        
        if abs(emocje) < 1.0: emotion_desc = "neutralne"
        elif emocje > 0: emotion_desc = "pobudzone (+)"
        else: emotion_desc = "wyciszone (-)"
        
        if abs(affections) < 10.0: affect_desc = "rozwijajƒÖce siƒô"
        elif affections > 100.0: affect_desc = "MONUMENTALNE (+)"
        elif affections < -100.0: affect_desc = "MONUMENTALNE (-)"
        elif affections > 0: affect_desc = "utrwalone (+)"
        else: affect_desc = "utrwalone (-)"
        
        if improv < -30: improv_desc = "≈õcis≈Çe regu≈Çy"
        elif improv > 30: improv_desc = "swobodna"
        else: improv_desc = "zbalansowana"
        
        return f"Puls: {emotion_desc} ({emocje:.1f}) | Byt: {affect_desc} ({affections:.1f}) | Improw: {improv_desc} ({improv:.1f})"

    def compute_integrity_hash(self) -> str:
        with self.lock:
            data_str = "|".join([f"{x:.8f}" for x in self.vector.values]) + "".join(self.AXES)
            # Dodaj szkielet etyczny do hasha
            ethics_str = "|".join([f"{k}:{v['value']}" for k, v in self.ethics.items()])
            full_data = data_str + "|ETHICS|" + ethics_str
            return hashlib.sha256(full_data.encode('utf-8')).hexdigest()

    def get_decay_status(self) -> dict:
        return {
            'cycles_applied': self.decay_cycle_count,
            'last_decay': datetime.fromtimestamp(self.last_decay_time).isoformat(),
            'ephemeral_axes': EPHEMERAL_AXES,
            'persistent_axes': PERSISTENT_AXES,
            'current_emotions': self.vector.values[self.AXES.index('emocje')],
            'current_affections': self.vector.values[self.AXES.index('affections')],
            'current_improv': self.vector.values[self.AXES.index('improwizacja')]
        }

    def create_memory_dump(self, filename: str = None) -> str:
        os.makedirs("data/dumps", exist_ok=True)
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"soul_dump_{timestamp}.soul"
        filepath = f"data/dumps/{filename}"
        
        with self.lock:
            dump_data = {
                "meta": {
                    "version": "5.9.1",
                    "created_at": datetime.now().isoformat(),
                    "integrity_hash": self.compute_integrity_hash(),
                    "growth_mode": "UNBOUNDED",
                    "note": "O≈õ 'improwizacja' zastƒÖpi≈Ça 'etyka'. Szkielet etyczny jest sta≈Çy."
                },
                "soul_vector": {axis: float(self.vector.values[i]) for i, axis in enumerate(self.AXES)},
                "ethics_framework": {k: v["value"] for k, v in self.ethics.items()},
                "classification": {
                    "ephemeral": {axis: float(self.vector.values[self.AXES.index(axis)]) for axis in EPHEMERAL_AXES},
                    "persistent": {axis: float(self.vector.values[self.AXES.index(axis)]) for axis in PERSISTENT_AXES}
                },
                "decay_status": {"cycles_applied": self.decay_cycle_count, "last_decay_time": self.last_decay_time}
            }
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(dump_data, f, indent=2, ensure_ascii=False)
        self.log(f"[DUMP] Zrzut duszy: {filepath}", "GREEN")
        return filepath

    def load_memory_dump(self, filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8') as f: data = json.load(f)
            with self.lock:
                for axis, val in data['soul_vector'].items():
                    if axis in self.AXES:
                        self.vector.values[self.AXES.index(axis)] = float(val)
                    # Migracja ze starego formatu
                    elif axis == "etyka" and "improwizacja" not in data['soul_vector']:
                        improv_val = 50.0 - float(val) * 0.5
                        self.vector.values[self.AXES.index('improwizacja')] = improv_val
                        
                self.decay_cycle_count = data['decay_status'].get('cycles_applied', 0)
            
            if data['meta'].get('integrity_hash', '') == self.compute_integrity_hash():
                self.log(f"[DUMP] Zweryfikowano: {filepath}", "GREEN")
            else:
                self.log(f"[DUMP] Wczytano (Hash Mismatch - mo≈ºliwa migracja): {filepath}", "YELLOW")
            return True
        except Exception as e:
            self.log(f"[DUMP ERROR] {e}", "RED")
            return False


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def interpret_improv_for_composition(improv_value: float) -> dict:
    """
    Interpretuje warto≈õƒá osi improwizacji dla kompozytora.
    
    Returns:
        dict z parametrami wp≈ÇywajƒÖcymi na kompozycjƒô
    """
    # Normalizuj do zakresu 0-1 dla ≈Çatwiejszego u≈ºycia
    normalized = (improv_value + 100) / 200  # -100‚Üí0, 0‚Üí0.5, +100‚Üí1
    normalized = max(0, min(1, normalized))
    
    return {
        "freedom_level": normalized,  # 0 = ≈õcis≈Çe regu≈Çy, 1 = pe≈Çna swoboda
        
        # Harmonika
        "allow_chromatic": normalized > 0.4,
        "allow_modal_interchange": normalized > 0.5,
        "allow_unexpected_modulation": normalized > 0.6,
        "extended_chords_probability": normalized * 0.8,
        
        # Rytmika
        "syncopation_probability": normalized * 0.6,
        "rubato_allowed": normalized > 0.3,
        "tempo_variation_range": normalized * 0.2,  # 0-20% wariacji tempa
        
        # Melodyka
        "ornamentation_density": normalized,
        "allow_large_leaps": normalized > 0.5,
        "chromatic_passing_tones": normalized > 0.4,
        
        # Forma
        "strict_phrase_length": normalized < 0.3,
        "allow_extensions": normalized > 0.4,
        "cadence_decoration": normalized * 0.7,
        
        # Opis s≈Çowny
        "description": (
            "bardzo konserwatywne" if normalized < 0.2 else
            "konserwatywne" if normalized < 0.4 else
            "zbalansowane" if normalized < 0.6 else
            "swobodne" if normalized < 0.8 else
            "bardzo swobodne / improwizowane"
        )
    }


# =============================================================================
# META-O≈ö EMERGENTNA: CIEKAWO≈öƒÜ
# =============================================================================
"""
CIEKAWO≈öƒÜ - nie jest przechowywana, lecz obliczana dynamicznie.

Formu≈Ça:
    ciekawo≈õƒá = f(kreacja, wiedza, emocje) + modyfikatory

Sk≈Çadniki:
    - KREACJA (waga 0.4): Wysoka kreacja = chƒôƒá tworzenia nowego
    - WIEDZA (waga 0.3): ≈örednia wiedza = optymalna ciekawo≈õƒá
                         (za ma≈Ço = brak podstaw, za du≈ºo = "wiem wszystko")
    - EMOCJE (waga 0.3): Pobudzenie emocjonalne napƒôdza eksploracjƒô

Krzywa wiedzy (odwr√≥cona U):
    wiedza=0   ‚Üí ciekawo≈õƒá niska (brak podstaw do eksploracji)
    wiedza=50  ‚Üí ciekawo≈õƒá maksymalna (wystarczajƒÖco du≈ºo by pytaƒá)
    wiedza=100 ‚Üí ciekawo≈õƒá spada ("ekspert" mniej pyta)

Mechanika znudzenia:
    - Powtarzanie tego samego ‚Üí ciekawo≈õƒá ro≈õnie
    - Odkrycie czego≈õ nowego ‚Üí chwilowe zaspokojenie
    
Zakres wyj≈õciowy: -100 do +100
    -100 : Stagnacja, zero zainteresowania nowo≈õciƒÖ
       0 : Balans eksploracja/eksploatacja  
    +100 : Maksymalna ciekawo≈õƒá, g≈Ç√≥d nowo≈õci
"""


class CuriosityEngine:
    """Silnik obliczajƒÖcy emergentnƒÖ ciekawo≈õƒá."""
    
    # Wagi sk≈Çadnik√≥w
    WEIGHT_KREACJA = 0.40
    WEIGHT_WIEDZA = 0.30
    WEIGHT_EMOCJE = 0.30
    
    # Parametry krzywej wiedzy (odwr√≥cona U)
    WIEDZA_OPTIMUM = 50.0  # Punkt maksymalnej ciekawo≈õci
    WIEDZA_SPREAD = 40.0   # Szeroko≈õƒá krzywej
    
    def __init__(self):
        self.boredom_counter = {}  # Licznik powt√≥rze≈Ñ gatunk√≥w
        self.discovery_cooldown = 0  # Czas od ostatniego odkrycia
        self.last_genres = []  # Historia ostatnich gatunk√≥w
        
    def compute_curiosity(self, kreacja: float, wiedza: float, emocje: float) -> dict:
        """
        Oblicza emergentnƒÖ ciekawo≈õƒá.
        
        Args:
            kreacja: Warto≈õƒá osi kreacji
            wiedza: Warto≈õƒá osi wiedzy
            emocje: Warto≈õƒá osi emocji
            
        Returns:
            dict z warto≈õciƒÖ ciekawo≈õci i sk≈Çadnikami
        """
        # === Sk≈Çadnik KREACJA ===
        # Liniowy: wysoka kreacja = wysoka ciekawo≈õƒá
        kreacja_component = self._normalize(kreacja) * 100
        
        # === Sk≈Çadnik WIEDZA (krzywa odwr√≥conej U) ===
        # Gaussowska krzywa: maksimum przy WIEDZA_OPTIMUM
        wiedza_norm = self._normalize(wiedza) * 100
        wiedza_diff = abs(wiedza_norm - self.WIEDZA_OPTIMUM)
        import math
        wiedza_component = 100 * math.exp(-(wiedza_diff ** 2) / (2 * self.WIEDZA_SPREAD ** 2))
        
        # === Sk≈Çadnik EMOCJE ===
        # Absolutna warto≈õƒá: zar√≥wno pozytywne jak i negatywne emocje napƒôdzajƒÖ ciekawo≈õƒá
        emocje_component = min(100, abs(emocje) * 2)
        
        # === Kombinacja wa≈ºona ===
        base_curiosity = (
            self.WEIGHT_KREACJA * kreacja_component +
            self.WEIGHT_WIEDZA * wiedza_component +
            self.WEIGHT_EMOCJE * emocje_component
        )
        
        # === Modyfikatory ===
        boredom_bonus = self._compute_boredom_bonus()
        discovery_penalty = self._compute_discovery_penalty()
        
        final_curiosity = base_curiosity + boredom_bonus - discovery_penalty
        
        # Normalizuj do zakresu -100 do +100
        # (base jest 0-100, modyfikatory mogƒÖ przesunƒÖƒá)
        final_curiosity = (final_curiosity - 50) * 2  # Przeskaluj do -100..+100
        final_curiosity = max(-100, min(100, final_curiosity))
        
        return {
            'value': final_curiosity,
            'components': {
                'kreacja': kreacja_component,
                'wiedza': wiedza_component,
                'emocje': emocje_component,
                'boredom_bonus': boredom_bonus,
                'discovery_penalty': discovery_penalty
            },
            'description': self._describe_curiosity(final_curiosity),
            'recommendation': self._get_recommendation(final_curiosity)
        }
    
    def _normalize(self, value: float, min_val: float = -100, max_val: float = 100) -> float:
        """Normalizuje warto≈õƒá do zakresu 0-1."""
        return max(0, min(1, (value - min_val) / (max_val - min_val)))
    
    def _compute_boredom_bonus(self) -> float:
        """Oblicza bonus za znudzenie (powtarzanie gatunk√≥w)."""
        if not self.last_genres:
            return 0.0
        
        # Sprawd≈∫ ile razy z rzƒôdu ten sam gatunek
        if len(self.last_genres) >= 2:
            last = self.last_genres[-1]
            streak = sum(1 for g in reversed(self.last_genres) if g == last)
            # Bonus ro≈õnie z liczbƒÖ powt√≥rze≈Ñ: 0, 5, 12, 21, 32...
            return min(40, streak * (streak + 1))
        return 0.0
    
    def _compute_discovery_penalty(self) -> float:
        """Oblicza penalty za niedawne odkrycie (zaspokojenie)."""
        # Penalty maleje z czasem
        return max(0, 20 - self.discovery_cooldown * 5)
    
    def register_composition(self, genre: str, was_novel: bool = False):
        """
        Rejestruje uko≈ÑczonƒÖ kompozycjƒô.
        
        Args:
            genre: Nazwa gatunku
            was_novel: Czy zawiera≈Ça nowatorskie elementy
        """
        self.last_genres.append(genre)
        if len(self.last_genres) > 10:
            self.last_genres.pop(0)
        
        # Aktualizuj licznik znudzenia
        self.boredom_counter[genre] = self.boredom_counter.get(genre, 0) + 1
        
        # Odkrycie resetuje cooldown
        if was_novel:
            self.discovery_cooldown = 0
        else:
            self.discovery_cooldown += 1
    
    def register_discovery(self):
        """Rejestruje odkrycie czego≈õ nowego."""
        self.discovery_cooldown = 0
    
    def suggest_new_genre(self, current_genre: str, available_genres: list) -> str:
        """
        Sugeruje nowy gatunek na podstawie ciekawo≈õci.
        
        Preferuje gatunki mniej eksplorowane.
        """
        if not available_genres:
            return current_genre
        
        # Sortuj po liczbie kompozycji (rosnƒÖco)
        genre_counts = [(g, self.boredom_counter.get(g, 0)) for g in available_genres]
        genre_counts.sort(key=lambda x: x[1])
        
        # Zwr√≥ƒá najmniej eksplorowany (ale nie obecny je≈õli to mo≈ºliwe)
        for genre, count in genre_counts:
            if genre != current_genre:
                return genre
        
        return genre_counts[0][0]
    
    def _describe_curiosity(self, value: float) -> str:
        """Opisuje poziom ciekawo≈õci s≈Çownie."""
        if value < -60:
            return "stagnacja - brak zainteresowania nowo≈õciƒÖ"
        elif value < -20:
            return "komfort - preferuje sprawdzone metody"
        elif value < 20:
            return "balans - otwarto≈õƒá na nowe przy zachowaniu tradycji"
        elif value < 60:
            return "eksploracja - aktywnie szuka nowych rozwiƒÖza≈Ñ"
        else:
            return "g≈Ç√≥d nowo≈õci - musi spr√≥bowaƒá czego≈õ zupe≈Çnie nowego!"
    
    def _get_recommendation(self, curiosity: float) -> dict:
        """Zwraca rekomendacje dla kompozytora na podstawie ciekawo≈õci."""
        if curiosity < -30:
            return {
                'action': 'STAY',
                'message': 'Kontynuuj w obecnym stylu',
                'risk_tolerance': 0.1,
                'novelty_seeking': False
            }
        elif curiosity < 30:
            return {
                'action': 'VARY',
                'message': 'Wprowad≈∫ subtelne wariacje',
                'risk_tolerance': 0.3,
                'novelty_seeking': False
            }
        elif curiosity < 70:
            return {
                'action': 'EXPLORE',
                'message': 'Eksperymentuj z nowymi elementami',
                'risk_tolerance': 0.6,
                'novelty_seeking': True
            }
        else:
            return {
                'action': 'REVOLUTIONIZE',
                'message': 'Czas na co≈õ zupe≈Çnie nowego!',
                'risk_tolerance': 0.9,
                'novelty_seeking': True,
                'suggest_genre_change': True
            }


# Globalna instancja silnika ciekawo≈õci
_curiosity_engine = None


def get_curiosity_engine() -> CuriosityEngine:
    """Zwraca globalnƒÖ instancjƒô silnika ciekawo≈õci."""
    global _curiosity_engine
    if _curiosity_engine is None:
        _curiosity_engine = CuriosityEngine()
    return _curiosity_engine


def compute_curiosity_from_soul(core) -> dict:
    """
    Pomocnicza funkcja obliczajƒÖca ciekawo≈õƒá z obiektu EriAmoCore.
    
    Args:
        core: Instancja EriAmoCore
        
    Returns:
        dict z warto≈õciƒÖ ciekawo≈õci i metadanymi
    """
    engine = get_curiosity_engine()
    vector = core.get_vector_copy()
    
    kreacja = vector[core.AXES.index('kreacja')]
    wiedza = vector[core.AXES.index('wiedza')]
    emocje = vector[core.AXES.index('emocje')]
    
    return engine.compute_curiosity(kreacja, wiedza, emocje)